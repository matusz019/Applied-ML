# Load required libraries
library(readr)
library(mice)
# Load train and test datasets
train_data <- read_csv("concrete_strength_train.csv")
test_data <- read_csv("concrete_strength_test.csv")
# Function to handle missing values
handle_missing_values <- function(data) {
# Examine missingness by column
col_missingness <- colMeans(is.na(data))
# Calculate average missingness
avg_missingness <- mean(col_missingness) * 100  # Convert to percentage
# Print average missingness
cat("Average missingness across columns:", avg_missingness, "%\n")
clean_train_data <- handle_missing_values(train_data)
clean_test_data <- handle_missing_values(test_data)
# Load required libraries
library(readr)
library(mice)
# Load train and test datasets
train_data <- read_csv("concrete_strength_train.csv")
test_data <- read_csv("concrete_strength_test.csv")
# Function to handle missing values
handle_missing_values <- function(data) {
# Examine missingness by column
col_missingness <- colMeans(is.na(data))
# Calculate average missingness
avg_missingness <- mean(col_missingness) * 100  # Convert to percentage
# Print average missingness
cat("Average missingness across columns:", avg_missingness, "%\n")
#if (avg_missingness > 1) {
# Impute missing values using mice
#cat("Imputing missing values using mice()...\n")
#imputed_data <- mice(data)
#return(imputed_data)
#} else {
# Remove missing values
#cat("Removing missing values...\n")
#clean_data <- na.omit(data)
# return(clean_data)
# }
}
# Apply the function to train and test datasets
clean_train_data <- handle_missing_values(train_data)
clean_test_data <- handle_missing_values(test_data)
# Univariate Outlier Detection
boxplot(concrete_strength_train$Cement, main = "Boxplot of Cement", ylab = "Cement", ylim = c(0, 600))
# Multivariate Outlier Detection
mahalanobis_distance <- mahalanobis(concrete_strength_train[, -9], colMeans(concrete_strength_train[, -9]), cov(concrete_strength_train[, -9]))
outlier_threshold <- qchisq(0.95, df = ncol(concrete_strength_train) - 1)
outlier_indices <- which(mahalanobis_distance > outlier_threshold)
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print indices of outliers
print(outlier_indices)
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print indices of outliers
print(outlier_indices)
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print outliers
outliers <- train_data[outlier_indices, ]
print(outliers)
concrete_strength_train <- read.csv("~/GitHub/Applied-ML/Coursework/concrete_strength_train.csv")
View(concrete_strength_train)
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print outliers
outliers <- train_data[outlier_indices, ]
print(outliers)
concrete_strength_train <- read.csv("~/GitHub/Applied-ML/Coursework/concrete_strength_train.csv")
View(concrete_strength_train)
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print outliers
outliers <- train_data[outlier_indices, ]
print(outliers)
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print outliers
if (length(outlier_indices) > 0) {
outliers <- train_data[outlier_indices, ]
print(outliers)
} else {
print("No outliers found.")
}
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print outliers
if (length(outlier_indices) > 0) {
outliers <- train_data[outlier_indices, ]
print(outliers)
}
else {
print("No outliers found.")
}
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print outliers
if (length(outlier_indices) > 0) {
outliers <- train_data[outlier_indices, ]
print(outliers)
}
else {
print("No outliers found.")
}
# Load required libraries
library(readr)
# Function to detect outliers based on Z-scores
detect_outliers <- function(data) {
# Calculate Z-scores for each variable
z_scores <- scale(data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Return indices of outliers
return(outlier_indices)
}
# Read train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Detect outliers in train dataset
train_outliers <- detect_outliers(train_data)
# Print indices of outliers in train dataset
cat("Outliers in train dataset:", train_outliers, "\n")
# Read test dataset
test_data <- read_csv("concrete_strength_test.csv")
# Detect outliers in test dataset
test_outliers <- detect_outliers(test_data)
# Print indices of outliers in test dataset
cat("Outliers in test dataset:", test_outliers, "\n")
# Load your dataset
# For example, if your dataset is a CSV file named "data.csv", you can load it using:
data <- read.csv("concrete_strength_test")
# Load your dataset
# For example, if your dataset is a CSV file named "data.csv", you can load it using:
data <- read.csv("concrete_strength_test.csv")
# Calculate the z-scores for the column 'Values'
data$z_scores <- scale(data$strength)
# Calculate the z-scores for the column 'Values'
data$z_scores <- scale(data$Strength)
# Load your dataset
# For example, if your dataset is a CSV file named "data.csv", you can load it using:
data <- read.csv("concrete_strength_test.csv")
# Calculate the z-scores for the column 'Values'
data$z_scores <- scale(data$Strength)
# Set a threshold for identifying outliers (e.g., z-score > 2 or z-score > 3)
threshold <- 2
# Identify outliers based on the threshold
outliers <- data[abs(data$z_scores) > threshold, ]
# Remove outliers from the dataset
data_clean <- data[abs(data$z_scores) <= threshold, ]
# Print the cleaned dataset
print(data_clean)
# Load your dataset
data <- read.csv("concrete_strength_test.csv")
# Function to identify outliers based on z-scores for each column
identify_outliers <- function(column, threshold) {
z_scores <- scale(column)  # Calculate z-scores
outliers <- abs(z_scores) > threshold  # Identify outliers
return(outliers)
}
# Set a threshold for identifying outliers (e.g., z-score > 2 or z-score > 3)
threshold <- 2
# Initialize a list to store outlier information for each column
outliers_list <- list()
# Loop through each column (excluding non-numeric columns)
for (col in names(data)) {
if (is.numeric(data[[col]])) {
outliers <- identify_outliers(data[[col]], threshold)  # Identify outliers for the column
outliers_list[[col]] <- outliers  # Store outlier information in the list
}
}
# Combine outlier information for all columns
combined_outliers <- Reduce("|", outliers_list)
# Remove outliers from the dataset
data_clean <- data[!combined_outliers, ]
# Print the cleaned dataset
print(data_clean)
# Load your dataset
trainData <- read.csv("concrete_strength_test.csv")
testData <- read.csv("concrete_strength_train.csv")
# Function to identify outliers based on z-scores for each column
identify_outliers <- function(column, threshold) {
z_scores <- scale(column)  # Calculate z-scores
outliers <- abs(z_scores) > threshold  # Identify outliers
return(outliers)
}
# Set a threshold for identifying outliers (e.g., z-score > 2 or z-score > 3)
threshold <- 2
# Initialize a list to store outlier information for each column
outliers_list <- list()
# Loop through each column (excluding non-numeric columns)
for (col in names(trainData)) {
if (is.numeric(trainData[[col]])) {
outliers <- identify_outliers(trainData[[col]], threshold)  # Identify outliers for the column
outliers_list[[col]] <- outliers  # Store outlier information in the list
}
}
# Combine outlier information for all columns
combined_outliers <- Reduce("|", outliers_list)
# Remove outliers from the dataset
trainData_clean <- trainData[!combined_outliers, ]
# Print the cleaned dataset
print(trainData_clean)
# Loop through each column (excluding non-numeric columns)
for (col in names(testData)) {
if (is.numeric(testData[[col]])) {
outliers <- identify_outliers(testData[[col]], threshold)  # Identify outliers for the column
outliers_list[[col]] <- outliers  # Store outlier information in the list
}
}
# Combine outlier information for all columns
combined_outliers <- Reduce("|", outliers_list)
# Remove outliers from the dataset
testData_clean <- testData[!combined_outliers, ]
# Print the cleaned dataset
print(testData_clean)
# Load the required library
library(readr)
# Read the dataset (replace "concrete_strength_train.csv" with your actual file name)
train_data <- read_csv("concrete_strength_train.csv")
# Select only predictor variables (exclude the target variable)
predictor_vars <- subset(train_data, select = -c(Strength))
# Compute the correlation matrix
correlation_matrix <- cor(predictor_vars)
# Print the correlation matrix
print(correlation_matrix)
# Select only predictor variables (exclude the target variable)
predictor_vars <- subset(trainData_clean, select = -c(Strength))
# Compute the correlation matrix
correlation_matrix <- cor(predictor_vars)
# Print the correlation matrix
print(correlation_matrix)
# Select only predictor variables (exclude the target variable)
predictor_vars <- subset(trainData_clean, select = -c(Strength))
# Compute the correlation matrix
correlation_matrix <- cor(predictor_vars)
# Print the correlation matrix
print(correlation_matrix)
# Load the training dataset
train <- read.csv("concrete_strength_train.csv")
# Display dimensions and column types
str(train)
# Summary statistics
summary_stats <- summary(train)
mean_value <- mean(train$Strength)
min_value <- min(train$Strength)
max_value <- max(train$Strength)
cov_value <- sd(train$Strength) / mean(train$Strength)  # Coefficient of variation
# Visual exploration of the Strength variable
library(ggplot2)
ggplot(train, aes(x = Strength)) +
geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
geom_text(aes(label = paste("Mean:", round(mean_value, 2), "\nMin:", min_value, "\nMax:", max_value, "\nCOV:", round(cov_value, 2))),
x = 0.8 * max(train$Strength), y = 0.8 * max(table(train$Strength)),
hjust = 0, vjust = -2, color = "black") +
labs(title = "Distribution of Concrete Strength in Training Dataset",
x = "Concrete Strength (MPa)",
y = "Frequency")
# Load the testing dataset
test <- read.csv("concrete_strength_test.csv")
# Display dimensions and column types
str(test)
# Summary statistics
summary_stats <- summary(test)
mean_value <- mean(test$Strength)
min_value <- min(test$Strength)
max_value <- max(test$Strength)
cov_value <- sd(test$Strength) / mean(test$Strength)  # Coefficient of variation
# Visual exploration of the Strength variable
ggplot(test, aes(x = Strength)) +
geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
geom_text(aes(label = paste("Mean:", round(mean_value, 2), "\nMin:", min_value, "\nMax:", max_value, "\nCOV:", round(cov_value, 2))),
x = 0.8 * max(test$Strength), y = 0.8 * max(table(test$Strength)),
hjust = 0, vjust = -2, color = "black") +
labs(title = "Distribution of Concrete Strength in Testing Dataset",
x = "Concrete Strength (MPa)",
y = "Frequency")
# Explanation/Interpretation
# The testing dataset consists of Z samples/rows and N columns.
# Similar to the training dataset, the variable Strength represents the concrete strength.
# It is also a numerical variable, indicating that regression modeling will be used to predict it.
# The distribution of concrete strength appears to be similar to that of the training dataset.
# The annotations in red provide additional information about the mean, min, max, and COV values.
# Load the training dataset
train <- read.csv("concrete_strength_train.csv")
# Calculate relative frequency
train_freq <- prop.table(table(train$Strength))
# Summary statistics
summary_stats <- summary(train)
mean_value <- mean(train$Strength)
min_value <- min(train$Strength)
max_value <- max(train$Strength)
cov_value <- sd(train$Strength) / mean(train$Strength)  # Coefficient of variation
# Visual exploration of the Strength variable
library(ggplot2)
ggplot(train, aes(x = Strength, y = ..density..)) +
geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
geom_text(data = data.frame(x = c(0.8 * max(train$Strength)), y = c(0.04), label = paste("Mean:", round(mean_value, 2), "\nMin:", min_value, "\nMax:", max_value, "\nCOV:", round(cov_value, 2))),
aes(x = x, y = y, label = label),
color = "red", hjust = 0, vjust = 1) +
labs(title = "Distribution of Concrete Strength in Training Dataset",
x = "Concrete Strength (MPa)",
y = "Relative Frequency",
caption = "Figure 1.1") +
theme(plot.caption = element_text(hjust = 0))
# Load the testing dataset
test <- read.csv("concrete_strength_test.csv")
# Calculate relative frequency
test_freq <- prop.table(table(test$Strength))
# Summary statistics
summary_stats <- summary(test)
mean_value <- mean(test$Strength)
min_value <- min(test$Strength)
max_value <- max(test$Strength)
cov_value <- sd(test$Strength) / mean(test$Strength)  # Coefficient of variation
# Visual exploration of the Strength variable
ggplot(test, aes(x = Strength, y = ..density..)) +
geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
geom_text(data = data.frame(x = c(0.8 * max(test$Strength)), y = c(0.04), label = paste("Mean:", round(mean_value, 2), "\nMin:", min_value, "\nMax:", max_value, "\nCOV:", round(cov_value, 2))),
aes(x = x, y = y, label = label),
color = "red", hjust = 0, vjust = 1) +
labs(title = "Distribution of Concrete Strength in Testing Dataset",
x = "Concrete Strength (MPa)",
y = "Relative Frequency",
caption = "Figure 1.1") +
theme(plot.caption = element_text(hjust = 0))
# Load the training dataset
train <- read.csv("concrete_strength_train.csv")
# Calculate relative frequency
train_freq <- prop.table(table(train$Strength))
# Summary statistics
summary_stats <- summary(train)
mean_value <- mean(train$Strength)
min_value <- min(train$Strength)
max_value <- max(train$Strength)
cov_value <- sd(train$Strength) / mean(train$Strength)  # Coefficient of variation
# Visual exploration of the Strength variable
library(ggplot2)
ggplot(train, aes(x = Strength, y = ..density..)) +
geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
geom_text(data = data.frame(x = c(0.8 * max(train$Strength)), y = c(0.04),
label = paste("Mean:", round(mean_value, 2),
"\nMin:", min_value, "\nMax:",
max_value, "\nCOV:", round(cov_value, 2))),
aes(x = x, y = y, label = label),
color = "red", hjust = 0, vjust = 1) +
labs(title = "Distribution of Concrete Strength in Training Dataset",
x = "Concrete Strength (MPa)",
y = "Relative Frequency",
caption = "Figure 1.1") +
theme(plot.caption = element_text(hjust = 0))
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load the testing dataset
test <- read.csv("concrete_strength_test.csv")
# Calculate relative frequency
test_freq <- prop.table(table(test$Strength))
# Summary statistics
summary_stats <- summary(test)
mean_value <- mean(test$Strength)
min_value <- min(test$Strength)
max_value <- max(test$Strength)
cov_value <- sd(test$Strength) / mean(test$Strength)  # Coefficient of variation
# Visual exploration of the Strength variable
ggplot(test, aes(x = Strength, y = ..density..)) +
geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
geom_text(data = data.frame(x = c(0.8 * max(test$Strength)), y = c(0.04), label = paste("Mean:", round(mean_value, 2), "\nMin:", min_value, "\nMax:", max_value, "\nCOV:", round(cov_value, 2))),
aes(x = x, y = y, label = label),
color = "red", hjust = 0, vjust = 1) +
labs(title = "Distribution of Concrete Strength in Testing Dataset",
x = "Concrete Strength (MPa)",
y = "Relative Frequency",
caption = "Figure 1.1") +
theme(plot.caption = element_text(hjust = 0))
# Load required libraries
library(readr)
library(dplyr)
library(FactoMineR)
library(ggplot2)
# Load train and test datasets
train_data <- read_csv("concrete_strength_train.csv")
test_data <- read_csv("concrete_strength_test.csv")
# Combine train and test datasets
all_data <- bind_rows(train_data, test_data)
# Separate features and target
X_all <- all_data %>% select(-`Strength`)
# Standardize the features
preprocess <- preProcess(X_all, method = c("center", "scale"))
# Load required libraries
library(readr)
library(dplyr)
library(FactoMineR)
library(ggplot2)
# Load train and test datasets
train_data <- read_csv("concrete_strength_train.csv")
test_data <- read_csv("concrete_strength_test.csv")
# Combine train and test datasets
all_data <- bind_rows(train_data, test_data)
# Separate features and target
X_all <- all_data %>% select(-`Strength`)
# Standardize the features
preprocess <- preProcess(X_all, method = c("center", "scale"))
# Load required libraries
library(caret)
library(readr)
library(dplyr)
library(FactoMineR)
library(ggplot2)
# Load train and test datasets
train_data <- read_csv("concrete_strength_train.csv")
test_data <- read_csv("concrete_strength_test.csv")
# Combine train and test datasets
all_data <- bind_rows(train_data, test_data)
# Separate features and target
X_all <- all_data %>% select(-`Strength`)
# Standardize the features
preprocess <- preProcess(X_all, method = c("center", "scale"))
X_all_scaled <- predict(preprocess, X_all)
# Perform PCA
pca_result <- PCA(X_all_scaled)
# Extract PCA scores
pca_scores <- pca_result$ind$coord
# Perform clustering
num_clusters <- 3  # Number of clusters
set.seed(123)  # For reproducibility
clusters <- kmeans(pca_scores, centers = num_clusters)
# Convert PCA scores matrix to data frame
pca_scores_df <- as.data.frame(pca_scores)
names(pca_scores_df) <- c("Dim.1", "Dim.2")
# Add cluster information to PCA scores data frame
pca_scores_df$Cluster <- as.factor(clusters$cluster)
# Calculate cluster centroids
cluster_centroids <- clusters$centers
# Convert cluster centroids to data frame and add Cluster column
cluster_centroids_df <- as.data.frame(cluster_centroids)
cluster_centroids_df$Cluster <- as.factor(1:num_clusters)  # Add Cluster column
# Plot PCA scores with clusters and centroids
ggplot() +
geom_point(data = pca_scores_df, aes(x = Dim.1, y = Dim.2, color = Cluster), shape = 21, size = 3) +
geom_point(data = cluster_centroids_df, aes(x = Dim.1, y = Dim.2, fill = Cluster), shape = 19, color = "black", size = 4) +
labs(x = "PC1",
y = "PC2",
title = "PCA Scores Plot with Clusters and Centroids") +
scale_fill_manual(values = c("red", "green", "blue")) +
scale_color_manual(values = c("red", "green", "blue")) +
theme_minimal()
