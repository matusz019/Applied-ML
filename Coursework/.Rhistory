pca_scores_df$Cluster <- as.factor(clusters$cluster)
# Calculate cluster centroids
cluster_centroids <- clusters$centers
# Plot PCA scores with clusters and centroids
ggplot() +
geom_point(data = pca_scores_df, aes(x = Dim.1, y = Dim.2, color = Cluster), shape = 21, size = 3) +
geom_point(data = as.data.frame(cluster_centroids), aes(x = Dim.1, y = Dim.2, fill = factor(1:num_clusters)), shape = 19, color = "black", size = 4) +
labs(x = "Principal Component 1",
y = "Principal Component 2",
title = "PCA Scores Plot with Clusters and Centroids") +
scale_fill_manual(values = c("blue", "black", "green")) +
scale_color_manual(values = c("blue", "black", "green")) +
theme_minimal()
# Load required libraries
library(readr)
library(dplyr)
library(FactoMineR)
library(ggplot2)
# Load train and test datasets
train_data <- read_csv("concrete_strength_train.csv")
test_data <- read_csv("concrete_strength_test.csv")
# Combine train and test datasets
all_data <- bind_rows(train_data, test_data)
# Separate features and target
X_all <- all_data %>% select(-`Strength`)
# Standardize the features
preprocess <- preProcess(X_all, method = c("center", "scale"))
X_all_scaled <- predict(preprocess, X_all)
# Perform PCA
pca_result <- PCA(X_all_scaled)
# Extract PCA scores
pca_scores <- pca_result$ind$coord
# Perform clustering
num_clusters <- 3  # Number of clusters
set.seed(123)  # For reproducibility
clusters <- kmeans(pca_scores, centers = num_clusters)
# Convert PCA scores matrix to data frame
pca_scores_df <- as.data.frame(pca_scores)
names(pca_scores_df) <- c("Dim.1", "Dim.2")
# Add cluster information to PCA scores data frame
pca_scores_df$Cluster <- as.factor(clusters$cluster)
# Calculate cluster centroids
cluster_centroids <- clusters$centers
# Plot PCA scores with clusters and centroids
ggplot() +
geom_point(data = pca_scores_df, aes(x = Dim.1, y = Dim.2, fill = Cluster), shape = 21, color = "black", size = 3) +
geom_point(data = as.data.frame(cluster_centroids), aes(x = Dim.1, y = Dim.2, fill = factor(1:num_clusters)), shape = 19, color = "black", size = 4) +
labs(x = "Principal Component 1",
y = "Principal Component 2",
title = "PCA Scores Plot with Clusters and Centroids") +
scale_fill_manual(values = c("blue", "black", "green")) +
theme_minimal()
# Load required libraries
library(readr)
library(dplyr)
library(FactoMineR)
library(ggplot2)
# Load train and test datasets
train_data <- read_csv("concrete_strength_train.csv")
test_data <- read_csv("concrete_strength_test.csv")
# Combine train and test datasets
all_data <- bind_rows(train_data, test_data)
# Separate features and target
X_all <- all_data %>% select(-`Strength`)
# Standardize the features
preprocess <- preProcess(X_all, method = c("center", "scale"))
X_all_scaled <- predict(preprocess, X_all)
# Perform PCA
pca_result <- PCA(X_all_scaled)
# Extract PCA scores
pca_scores <- pca_result$ind$coord
# Perform clustering
num_clusters <- 3  # Number of clusters
set.seed(123)  # For reproducibility
clusters <- kmeans(pca_scores, centers = num_clusters)
# Convert PCA scores matrix to data frame
pca_scores_df <- as.data.frame(pca_scores)
names(pca_scores_df) <- c("Dim.1", "Dim.2")
# Add cluster information to PCA scores data frame
pca_scores_df$Cluster <- as.factor(clusters$cluster)
# Calculate cluster centroids
cluster_centroids <- clusters$centers
# Plot PCA scores with clusters and centroids
ggplot() +
geom_point(data = pca_scores_df, aes(x = Dim.1, y = Dim.2, fill = Cluster), shape = 21, color = "black", size = 3) +
geom_point(data = as.data.frame(cluster_centroids), aes(x = Dim.1, y = Dim.2, fill = factor(1:num_clusters)), shape = 19, color = "black", size = 4) +
labs(x = "Principal Component 1",
y = "Principal Component 2",
title = "PCA Scores Plot with Clusters and Centroids") +
scale_fill_manual(values = c("blue", "black", "green")) +
# Load required libraries
library(readr)
# Load required libraries
library(readr)
library(dplyr)
library(FactoMineR)
library(ggplot2)
# Load train and test datasets
train_data <- read_csv("concrete_strength_train.csv")
test_data <- read_csv("concrete_strength_test.csv")
# Combine train and test datasets
all_data <- bind_rows(train_data, test_data)
# Separate features and target
X_all <- all_data %>% select(-`Strength`)
# Standardize the features
preprocess <- preProcess(X_all, method = c("center", "scale"))
X_all_scaled <- predict(preprocess, X_all)
# Perform PCA
pca_result <- PCA(X_all_scaled)
# Extract PCA scores
pca_scores <- pca_result$ind$coord
# Perform clustering
num_clusters <- 3  # Number of clusters
set.seed(123)  # For reproducibility
clusters <- kmeans(pca_scores, centers = num_clusters)
# Convert PCA scores matrix to data frame
pca_scores_df <- as.data.frame(pca_scores)
names(pca_scores_df) <- c("Dim.1", "Dim.2")
# Add cluster information to PCA scores data frame
pca_scores_df$Cluster <- as.factor(clusters$cluster)
# Calculate cluster centroids
cluster_centroids <- clusters$centers
# Plot PCA scores with clusters and centroids
ggplot() +
geom_point(data = pca_scores_df, aes(x = Dim.1, y = Dim.2, color = Cluster), shape = 21, size = 3) +
geom_point(data = as.data.frame(cluster_centroids), aes(x = Dim.1, y = Dim.2, fill = factor(1:num_clusters)), shape = 19, color = "black", size = 4) +
labs(x = "Principal Component 1",
y = "Principal Component 2",
title = "PCA Scores Plot with Clusters and Centroids") +
scale_fill_manual(values = c("blue", "black", "green")) +
scale_color_manual(values = c("blue", "black", "green")) +
theme_minimal()
# Load required libraries
library(readr)
library(dplyr)
library(FactoMineR)
library(ggplot2)
# Load train and test datasets
train_data <- read_csv("concrete_strength_train.csv")
test_data <- read_csv("concrete_strength_test.csv")
# Combine train and test datasets
all_data <- bind_rows(train_data, test_data)
# Separate features and target
X_all <- all_data %>% select(-`Strength`)
# Standardize the features
preprocess <- preProcess(X_all, method = c("center", "scale"))
X_all_scaled <- predict(preprocess, X_all)
# Perform PCA
pca_result <- PCA(X_all_scaled)
# Extract PCA scores
pca_scores <- pca_result$ind$coord
# Perform clustering
num_clusters <- 3  # Number of clusters
set.seed(123)  # For reproducibility
clusters <- kmeans(pca_scores, centers = num_clusters)
# Convert PCA scores matrix to data frame
pca_scores_df <- as.data.frame(pca_scores)
names(pca_scores_df) <- c("Dim.1", "Dim.2")
# Add cluster information to PCA scores data frame
pca_scores_df$Cluster <- as.factor(clusters$cluster)
# Calculate cluster centroids
cluster_centroids <- clusters$centers
# Convert cluster centroids to data frame and add Cluster column
cluster_centroids_df <- as.data.frame(cluster_centroids)
cluster_centroids_df$Cluster <- as.factor(1:num_clusters)  # Add Cluster column
# Plot PCA scores with clusters and centroids
ggplot() +
geom_point(data = pca_scores_df, aes(x = Dim.1, y = Dim.2, color = Cluster), shape = 21, size = 3) +
geom_point(data = cluster_centroids_df, aes(x = Dim.1, y = Dim.2, fill = Cluster), shape = 19, color = "black", size = 4) +
labs(x = "Principal Component 1",
y = "Principal Component 2",
title = "PCA Scores Plot with Clusters and Centroids") +
scale_fill_manual(values = c("red", "green", "blue")) +
scale_color_manual(values = c("red", "green", "blue")) +
theme_minimal()
# Load required libraries
library(readr)
library(dplyr)
library(FactoMineR)
library(ggplot2)
# Load train and test datasets
train_data <- read_csv("concrete_strength_train.csv")
test_data <- read_csv("concrete_strength_test.csv")
# Combine train and test datasets
all_data <- bind_rows(train_data, test_data)
# Separate features and target
X_all <- all_data %>% select(-`Strength`)
# Standardize the features
preprocess <- preProcess(X_all, method = c("center", "scale"))
X_all_scaled <- predict(preprocess, X_all)
# Perform PCA
pca_result <- PCA(X_all_scaled)
# Extract PCA scores
pca_scores <- pca_result$ind$coord
# Perform clustering
num_clusters <- 3  # Number of clusters
set.seed(123)  # For reproducibility
clusters <- kmeans(pca_scores, centers = num_clusters)
# Convert PCA scores matrix to data frame
pca_scores_df <- as.data.frame(pca_scores)
names(pca_scores_df) <- c("Dim.1", "Dim.2")
# Add cluster information to PCA scores data frame
pca_scores_df$Cluster <- as.factor(clusters$cluster)
# Calculate cluster centroids
cluster_centroids <- clusters$centers
# Convert cluster centroids to data frame and add Cluster column
cluster_centroids_df <- as.data.frame(cluster_centroids)
cluster_centroids_df$Cluster <- as.factor(1:num_clusters)  # Add Cluster column
# Plot PCA scores with clusters and centroids
ggplot() +
geom_point(data = pca_scores_df, aes(x = Dim.1, y = Dim.2, color = Cluster), shape = 21, size = 3) +
geom_point(data = cluster_centroids_df, aes(x = Dim.1, y = Dim.2, fill = Cluster), shape = 19, color = "black", size = 4) +
labs(x = "Hydration",
y = "Strength",
title = "PCA Scores Plot with Clusters and Centroids") +
scale_fill_manual(values = c("red", "green", "blue")) +
scale_color_manual(values = c("red", "green", "blue")) +
theme_minimal()
# Load required libraries
library(readr)
library(dplyr)
library(FactoMineR)
library(ggplot2)
# Load train and test datasets
train_data <- read_csv("concrete_strength_train.csv")
test_data <- read_csv("concrete_strength_test.csv")
# Combine train and test datasets
all_data <- bind_rows(train_data, test_data)
# Separate features and target
X_all <- all_data %>% select(-`Strength`)
# Standardize the features
preprocess <- preProcess(X_all, method = c("center", "scale"))
X_all_scaled <- predict(preprocess, X_all)
# Perform PCA
pca_result <- PCA(X_all_scaled)
# Extract PCA scores
pca_scores <- pca_result$ind$coord
# Perform clustering
num_clusters <- 3  # Number of clusters
set.seed(123)  # For reproducibility
clusters <- kmeans(pca_scores, centers = num_clusters)
# Convert PCA scores matrix to data frame
pca_scores_df <- as.data.frame(pca_scores)
names(pca_scores_df) <- c("Dim.1", "Dim.2")
# Add cluster information to PCA scores data frame
pca_scores_df$Cluster <- as.factor(clusters$cluster)
# Calculate cluster centroids
cluster_centroids <- clusters$centers
# Convert cluster centroids to data frame and add Cluster column
cluster_centroids_df <- as.data.frame(cluster_centroids)
cluster_centroids_df$Cluster <- as.factor(1:num_clusters)  # Add Cluster column
# Plot PCA scores with clusters and centroids
ggplot() +
geom_point(data = pca_scores_df, aes(x = Dim.1, y = Dim.2, color = Cluster), shape = 21, size = 3) +
geom_point(data = cluster_centroids_df, aes(x = Dim.1, y = Dim.2, fill = Cluster), shape = 19, color = "black", size = 4) +
labs(x = "PC1",
y = "PC2",
title = "PCA Scores Plot with Clusters and Centroids") +
scale_fill_manual(values = c("red", "green", "blue")) +
scale_color_manual(values = c("red", "green", "blue")) +
theme_minimal()
library(readr)
library(dplyr)
library(mice)
# Load train and test datasets
train_data <- read_csv("concrete_strength_train.csv")
test_data <- read_csv("concrete_strength_test.csv")
# Function to assess missingness and decide whether to impute or remove
assess_missingness <- function(data) {
# Column-wise missingness
col_missingness <- colMeans(is.na(data))
# Overall missingness
overall_missingness <- mean(col_missingness)
if (overall_missingness > 0.01) {  # Average missingness > 1%
# Impute missing values using mice
imputed_data <- mice(data)
return(imputed_data)
} else {
# Remove missing values
clean_data <- na.omit(data)
return(clean_data)
}
}
# Apply the function to both train and test datasets
clean_train_data <- assess_missingness(train_data)
clean_test_data <- assess_missingness(test_data)
# Load required libraries
library(readr)
library(mice)
# Load train and test datasets
train_data <- read_csv("concrete_strength_train.csv")
test_data <- read_csv("concrete_strength_test.csv")
# Function to handle missing values
handle_missing_values <- function(data) {
# Examine missingness by column
col_missingness <- colMeans(is.na(data))
# Calculate average missingness
avg_missingness <- mean(col_missingness) * 100  # Convert to percentage
# Print average missingness
cat("Average missingness across columns:", avg_missingness, "%\n")
if (avg_missingness > 1) {
# Impute missing values using mice
cat("Imputing missing values using mice()...\n")
imputed_data <- mice(data)
return(imputed_data)
} else {
# Remove missing values
cat("Removing missing values...\n")
clean_data <- na.omit(data)
return(clean_data)
}
}
# Apply the function to train and test datasets
clean_train_data <- handle_missing_values(train_data)
clean_test_data <- handle_missing_values(test_data)
View(clean_train_data)
# Load required libraries
library(readr)
library(mice)
# Load train and test datasets
train_data <- read_csv("concrete_strength_train.csv")
test_data <- read_csv("concrete_strength_test.csv")
# Function to handle missing values
handle_missing_values <- function(data) {
# Examine missingness by column
col_missingness <- colMeans(is.na(data))
# Calculate average missingness
avg_missingness <- mean(col_missingness) * 100  # Convert to percentage
# Print average missingness
cat("Average missingness across columns:", avg_missingness, "%\n")
clean_train_data <- handle_missing_values(train_data)
clean_test_data <- handle_missing_values(test_data)
# Load required libraries
library(readr)
library(mice)
# Load train and test datasets
train_data <- read_csv("concrete_strength_train.csv")
test_data <- read_csv("concrete_strength_test.csv")
# Function to handle missing values
handle_missing_values <- function(data) {
# Examine missingness by column
col_missingness <- colMeans(is.na(data))
# Calculate average missingness
avg_missingness <- mean(col_missingness) * 100  # Convert to percentage
# Print average missingness
cat("Average missingness across columns:", avg_missingness, "%\n")
#if (avg_missingness > 1) {
# Impute missing values using mice
#cat("Imputing missing values using mice()...\n")
#imputed_data <- mice(data)
#return(imputed_data)
#} else {
# Remove missing values
#cat("Removing missing values...\n")
#clean_data <- na.omit(data)
# return(clean_data)
# }
}
# Apply the function to train and test datasets
clean_train_data <- handle_missing_values(train_data)
clean_test_data <- handle_missing_values(test_data)
# Univariate Outlier Detection
boxplot(concrete_strength_train$Cement, main = "Boxplot of Cement", ylab = "Cement", ylim = c(0, 600))
# Multivariate Outlier Detection
mahalanobis_distance <- mahalanobis(concrete_strength_train[, -9], colMeans(concrete_strength_train[, -9]), cov(concrete_strength_train[, -9]))
outlier_threshold <- qchisq(0.95, df = ncol(concrete_strength_train) - 1)
outlier_indices <- which(mahalanobis_distance > outlier_threshold)
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print indices of outliers
print(outlier_indices)
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print indices of outliers
print(outlier_indices)
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print outliers
outliers <- train_data[outlier_indices, ]
print(outliers)
concrete_strength_train <- read.csv("~/GitHub/Applied-ML/Coursework/concrete_strength_train.csv")
View(concrete_strength_train)
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print outliers
outliers <- train_data[outlier_indices, ]
print(outliers)
concrete_strength_train <- read.csv("~/GitHub/Applied-ML/Coursework/concrete_strength_train.csv")
View(concrete_strength_train)
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print outliers
outliers <- train_data[outlier_indices, ]
print(outliers)
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print outliers
if (length(outlier_indices) > 0) {
outliers <- train_data[outlier_indices, ]
print(outliers)
} else {
print("No outliers found.")
}
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print outliers
if (length(outlier_indices) > 0) {
outliers <- train_data[outlier_indices, ]
print(outliers)
}
else {
print("No outliers found.")
}
# Load required library
library(readr)
# Read the train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Calculate Z-scores for each variable
z_scores <- scale(train_data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Print outliers
if (length(outlier_indices) > 0) {
outliers <- train_data[outlier_indices, ]
print(outliers)
}
else {
print("No outliers found.")
}
# Load required libraries
library(readr)
# Function to detect outliers based on Z-scores
detect_outliers <- function(data) {
# Calculate Z-scores for each variable
z_scores <- scale(data[, -9])  # Excluding the target variable "Strength"
# Define Z-score threshold
z_score_threshold <- 3
# Identify outliers based on Z-scores
outlier_indices <- which(apply(abs(z_scores) > z_score_threshold, 1, any))
# Return indices of outliers
return(outlier_indices)
}
# Read train dataset
train_data <- read_csv("concrete_strength_train.csv")
# Detect outliers in train dataset
train_outliers <- detect_outliers(train_data)
# Print indices of outliers in train dataset
cat("Outliers in train dataset:", train_outliers, "\n")
# Read test dataset
test_data <- read_csv("concrete_strength_test.csv")
# Detect outliers in test dataset
test_outliers <- detect_outliers(test_data)
# Print indices of outliers in test dataset
cat("Outliers in test dataset:", test_outliers, "\n")
